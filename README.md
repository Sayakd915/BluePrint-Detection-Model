---
sdk: docker
app_port: 8000
---

# BluePrint-Detection-Model

## Overview

The BluePrint-Detection-Model is designed to identify and localize windows and doors in blueprint images. It uses a fine-tuned YOLOv8s model trained on a custom dataset of blueprints. The API accepts image uploads and returns bounding box coordinates, labels (`window` or `door`), and confidence scores for detected objects.

## Directory structure

/images/ : Contains all the training images
/labels/ : Contains all the related labels
/runs/ : Contains the trained weights and metrics
/Dockerfile : Docker File to deploy api on HuggingFace Spaces
/classes.txt : Mentions all the classes available in the annotations
/main.py : The main api file
/training metrics.png : Combined training metrics for the model

Some files that are not in the main branch are train.py, preprocess.py and visualization.py. These files are available in their model specific branches (yolov8s and yolov8n). The main branch utilises the yolov8s weights.

## Procedure :
1. Annotation was done using RoboFlow Manual Annotation tool (as labelImg gave segmentation fault for windsurf) :

![Screenshot From 2025-05-27 17-59-11](https://github.com/user-attachments/assets/64e76751-351f-4f98-af3b-11efab824fcf)
![Screenshot From 2025-05-27 17-46-26](https://github.com/user-attachments/assets/a9985017-b11a-40e0-985a-1fca9a4b6b31)

The labels were stored in yolov8 format : 

![image](https://github.com/user-attachments/assets/542ab8de-ca21-4906-b0ba-6e91e7194674)

2.Tiling was used to segment larger blueprint images into smaller parts to make sure the model can somewhat detect the doors and windows peroperly. The dataset was then split 80/20 into train and val sets and dataset.yaml was generated. (Check preprocess.py for respective branches)

3. The model was trained using two yolov8-based models : yolov8 nano and yolov8 small. yolov8s showed better precision-recall and slightly better mAP than yolov8n. However, due to the lack enough images ( trained only on 15 images ), the model fails to generalize well to data. This can be resolved by adding more data (especially recall scores for window class). (Check train.py for respective branches)

![Screenshot From 2025-05-28 01-42-14](https://github.com/user-attachments/assets/cfdbfe56-4393-4b0a-ac31-08beaccc7d3a)
![Screenshot From 2025-05-28 01-42-31](https://github.com/user-attachments/assets/27067620-6189-4945-ac4f-2e555b1ecc5e)

4. The metrics were stored in results.csv in respective branches and matplotlib was used for visualization of the same. (Check visualization.py)

## API details 

The public API is available at : https://Sayakdas915-blueprint-api.hf.space

The API was generated by wrapping the testing script by FastAPI. The docs are available at https://Sayakdas915-blueprint-api.hf.space/docs

The API was tested using curl on a test image :

![Screenshot From 2025-05-28 21-27-23](https://github.com/user-attachments/assets/4e607e7f-f1ba-41e6-827e-3fe3c862cc50)

The response was returned in 10 seconds.

Loom Video Link ( contains procedure overview and testing ) : https://www.loom.com/share/8b376750a7f146458aa711126d553c78?sid=ab29e7a7-3bb6-4dc4-b246-05c8278ead4c
